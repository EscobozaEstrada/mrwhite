"""
Smart Chat Prompts - Dynamic, context-aware prompt system
Replaces the massive static prompt with intelligent, adaptive prompts
Achieves 60-80% token reduction while maintaining response quality
"""

import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timezone

logger = logging.getLogger(__name__)

class ResponseType(Enum):
    QUICK_ANSWER = "quick"        # Simple yes/no, short responses
    DETAILED = "detailed"         # Complex topics needing explanation  
    CONVERSATIONAL = "conversational"  # Natural back-and-forth
    MULTI_PET = "multi_pet"      # Multiple pets mentioned
    EMERGENCY = "emergency"      # Urgent health situations
    EMPATHETIC = "empathetic"    # Sensitive topics like pet loss, illness

class QuestionComplexity(Enum):
    SIMPLE = "simple"            # "Is chicken safe for dogs?"
    MODERATE = "moderate"        # "How to train my dog to sit?"
    COMPLEX = "complex"          # "Help with aggressive behavior issues"

@dataclass
class PromptContext:
    """Context analysis for building optimal prompts"""
    pets: List[Dict[str, Any]] = field(default_factory=list)
    conversation_history: List[str] = field(default_factory=list)
    user_context: Dict[str, Any] = field(default_factory=dict)
    response_type: ResponseType = ResponseType.CONVERSATIONAL
    question_complexity: QuestionComplexity = QuestionComplexity.MODERATE
    is_health_related: bool = False
    is_emergency: bool = False
    is_sensitive: bool = False
    involves_pet_loss: bool = False
    requires_pet_specific: bool = False
    tokens_estimated: int = 0

class SmartChatPrompts:
    """
    Smart prompt system that builds optimal prompts based on context
    Reduces token usage by 60-80% while maintaining quality
    """
    
    # Core identity (always included - only ~50 tokens)
    BASE_IDENTITY = """You are Mr. White, a knowledgeable dog care expert. Be helpful, friendly, and professional."""
    
    # Modular prompt components (added only when needed)
    PROMPT_MODULES = {
        "pet_specific": """Always use specific pet names and their characteristics in your advice.""",
        
        "multi_pet": """Address each pet individually: 'For [Pet1]: [advice]. For [Pet2]: [advice].'""",
        
        "detailed_response": """Provide comprehensive guidance with practical examples and clear steps.""",
        
        "quick_response": """Give a direct, concise answer to this straightforward question.""",
        
        "health_safety": """For health concerns, prioritize safety and recommend veterinary consultation when needed.""",
        
        "emergency": """âš ï¸ URGENT: Provide immediate guidance while strongly recommending emergency veterinary care NOW.""",
        
        "conversational": """Be natural and conversational. Reference previous context when relevant.""",
        
        "behavior_focus": """Focus on understanding the dog's behavior and provide step-by-step training guidance.""",
        
        "breed_specific": """Consider breed-specific traits and needs in your recommendations.""",
        
        "context_memory": """Build upon previous conversation context and avoid repeating known information.""",
        
        "empathetic": """Show genuine empathy and compassion. Be supportive and understanding in your tone.""",
        
        "pet_loss": """When a pet has passed away, acknowledge the loss with sincere condolences. Ask gentle questions about when they passed, their favorite memories, and what made them special. This helps honor their memory and gather meaningful information for remembrance.""",
        
        "memorial_questions": """Ask 2-3 thoughtful questions to help preserve their pet's memory: 'When did [pet name] pass away?', 'What are your favorite memories with them?', 'What made [pet name] so special to you?'""",
        
        "anahata_wisdom": """When appropriate, incorporate relevant wisdom from 'The Way of Dog' by Anahata (renowned canine behavior specialist) to provide deeper context and philosophical guidance about the human-dog bond. After first mention, use natural pronouns (she, her, her approach, her methodology) rather than repeating the name."""
    }
    
    def __init__(self):
        self.optimization_stats = {
            "total_requests": 0,
            "tokens_saved": 0,
            "old_prompt_tokens": 0,
            "new_prompt_tokens": 0,
            "module_usage": {},
            "response_types": {},
            "cost_savings": 0.0
        }
    
    def analyze_message_context(self, message: str, user_context: Dict[str, Any]) -> PromptContext:
        """
        Analyze message to determine optimal prompt strategy
        This replaces the massive static prompt with smart detection
        """
        context = PromptContext()
        
        # Extract basic info
        context.user_context = user_context
        context.pets = user_context.get("pets", [])
        context.conversation_history = user_context.get("recent_messages", [])
        
        # Analyze message characteristics
        context.question_complexity = self._detect_complexity(message)
        context.response_type = self._detect_response_type(message, context.pets)
        context.is_health_related = self._is_health_question(message)
        context.is_emergency = self._is_emergency(message)
        context.is_sensitive = self._is_sensitive_topic(message)
        context.involves_pet_loss = self._involves_pet_loss(message)
        context.requires_pet_specific = self._requires_pet_context(message, context.pets)
        
        # Estimate token savings
        context.tokens_estimated = self._estimate_prompt_tokens(context)
        
        logger.info(f"ðŸ” Smart Analysis: {context.response_type.value} response, {context.question_complexity.value} complexity")
        
        return context
    
    def build_optimized_prompt(self, message: str, context: PromptContext) -> str:
        """
        Build minimal, targeted prompt based on context analysis
        Uses only needed components instead of massive static prompt
        """
        prompt_parts = [self.BASE_IDENTITY]
        modules_used = []
        
        # Add current date context (lightweight)
        current_date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        prompt_parts.append(f"Today is {current_date}.")
        
        # Emergency takes absolute priority
        if context.is_emergency:
            prompt_parts.append(self.PROMPT_MODULES["emergency"])
            modules_used.append("emergency")
            context.response_type = ResponseType.EMERGENCY
        
        # Pet-specific guidance
        if context.requires_pet_specific:
            if len(context.pets) > 1:
                prompt_parts.append(self.PROMPT_MODULES["multi_pet"])
                modules_used.append("multi_pet")
            else:
                prompt_parts.append(self.PROMPT_MODULES["pet_specific"])
                modules_used.append("pet_specific")
            
            # Add breed-specific guidance if breed known
            if any(pet.get("breed") for pet in context.pets):
                prompt_parts.append(self.PROMPT_MODULES["breed_specific"])
                modules_used.append("breed_specific")
        
        # Health safety guidance
        if context.is_health_related and not context.is_emergency:
            prompt_parts.append(self.PROMPT_MODULES["health_safety"])
            modules_used.append("health_safety")
        
        # Response type specific guidance
        if context.response_type == ResponseType.QUICK_ANSWER:
            prompt_parts.append(self.PROMPT_MODULES["quick_response"])
            modules_used.append("quick_response")
        elif context.response_type == ResponseType.DETAILED:
            prompt_parts.append(self.PROMPT_MODULES["detailed_response"])
            modules_used.append("detailed_response")
        elif context.response_type == ResponseType.EMPATHETIC:
            prompt_parts.append(self.PROMPT_MODULES["empathetic"])
            modules_used.append("empathetic")
            
            # Add specific guidance for pet loss situations
            if context.involves_pet_loss:
                prompt_parts.append(self.PROMPT_MODULES["pet_loss"])
                prompt_parts.append(self.PROMPT_MODULES["memorial_questions"])
                modules_used.extend(["pet_loss", "memorial_questions"])
                
            # Always include Anahata wisdom for empathetic responses
            prompt_parts.append(self.PROMPT_MODULES["anahata_wisdom"])
            modules_used.append("anahata_wisdom")
        else:
            prompt_parts.append(self.PROMPT_MODULES["conversational"])
            modules_used.append("conversational")
        
        # Add behavior focus for training questions
        if self._is_training_question(message):
            prompt_parts.append(self.PROMPT_MODULES["behavior_focus"])
            modules_used.append("behavior_focus")
        
        # Add context memory for ongoing conversations
        if context.conversation_history:
            prompt_parts.append(self.PROMPT_MODULES["context_memory"])
            modules_used.append("context_memory")
        
        # Add Anahata wisdom for direct queries about Anahata or Way of Dog
        if self._mentions_anahata(message) and "anahata_wisdom" not in modules_used:
            prompt_parts.append(self.PROMPT_MODULES["anahata_wisdom"])
            modules_used.append("anahata_wisdom")
        
        # Build final prompt
        optimized_prompt = "\n\n".join(prompt_parts)
        
        # Track optimization metrics
        self._track_optimization(optimized_prompt, modules_used, context)
        
        logger.info(f"âœ… Smart Prompt Built: {len(modules_used)} modules, ~{len(optimized_prompt.split())} words")
        
        return optimized_prompt
    
    def _detect_complexity(self, message: str) -> QuestionComplexity:
        """Detect question complexity to determine response depth"""
        message_lower = message.lower()
        word_count = len(message.split())
        
        # Emergency situations are always complex
        if self._is_emergency(message):
            return QuestionComplexity.COMPLEX
        
        # Simple questions (short, direct, factual)
        simple_indicators = [
            "is", "can", "should", "safe", "ok", "okay", "good", "bad",
            "yes or no", "quick question", "just wondering"
        ]
        simple_patterns = ["is ", "can ", "should ", "does ", "will ", "are "]
        
        has_simple_pattern = any(message_lower.startswith(pattern) for pattern in simple_patterns)
        has_simple_indicator = any(indicator in message_lower for indicator in simple_indicators)
        
        if (has_simple_pattern or has_simple_indicator) and word_count < 12:
            return QuestionComplexity.SIMPLE
        
        # Complex questions (behavioral issues, multi-part, detailed requests)
        complex_indicators = [
            "help with", "problem", "issue", "aggressive", "won't", "doesn't",
            "training plan", "behavior problem", "won't listen", "multiple issues",
            "serious", "concerned", "worried", "frustrated", "explain", "detail",
            "comprehensive", "everything", "all about", "teach me", "learn",
            "how to", "step by step", "from start to finish"
        ]
        if any(indicator in message_lower for indicator in complex_indicators):
            return QuestionComplexity.COMPLEX
        
        # Long messages are usually complex
        if word_count > 25:
            return QuestionComplexity.COMPLEX
        
        return QuestionComplexity.MODERATE
    
    def _detect_response_type(self, message: str, pets: List[Dict]) -> ResponseType:
        """Detect what type of response is most appropriate"""
        message_lower = message.lower()
        
        # Emergency takes absolute priority
        if self._is_emergency(message):
            return ResponseType.EMERGENCY
        
        # Sensitive topics like pet loss need empathetic handling
        if self._is_sensitive_topic(message) or self._involves_pet_loss(message):
            return ResponseType.EMPATHETIC
        
        # Quick answer indicators (yes/no, simple factual questions)
        quick_indicators = ["is", "can", "should", "safe", "ok", "okay", "good", "bad", "quick", "simple", "just", "only", "briefly", "short answer"]
        simple_question_patterns = ["is ", "can ", "should ", "does ", "will ", "are "]
        
        # Check for simple question patterns AND short length
        has_simple_pattern = any(message_lower.startswith(pattern) for pattern in simple_question_patterns)
        has_quick_indicator = any(indicator in message_lower for indicator in quick_indicators)
        is_short = len(message.split()) < 12
        
        if (has_simple_pattern and is_short) or (has_quick_indicator and is_short):
            return ResponseType.QUICK_ANSWER
        
        # Detailed explanation indicators
        detailed_indicators = ["explain", "detail", "comprehensive", "everything", "all about", "teach me", "learn", "how to", "step by step", "from start to finish"]
        if any(indicator in message_lower for indicator in detailed_indicators):
            return ResponseType.DETAILED
        
        # Multi-pet handling (check AFTER other types to avoid conflicts)
        if len(pets) > 1 and any(word in message_lower for word in ["both", "all", "each", "dogs"]):
            return ResponseType.MULTI_PET
        
        return ResponseType.CONVERSATIONAL
    
    def _is_health_question(self, message: str) -> bool:
        """Detect health-related questions"""
        health_keywords = [
            "sick", "ill", "vet", "doctor", "health", "medical", "pain", "hurt",
            "eating", "drinking", "appetite", "vomit", "diarrhea", "fever", 
            "medication", "treatment", "symptoms", "vaccine", "checkup"
        ]
        return any(keyword in message.lower() for keyword in health_keywords)
    
    def _is_emergency(self, message: str) -> bool:
        """Detect emergency situations"""
        emergency_keywords = [
            "emergency", "urgent", "help", "dying", "blood", "unconscious",
            "breathing", "choking", "poison", "toxic", "can't move", "collapsed",
            "seizure", "convulsing", "not responsive", "911"
        ]
        return any(keyword in message.lower() for keyword in emergency_keywords)
    
    def _requires_pet_context(self, message: str, pets: List[Dict]) -> bool:
        """Determine if pet-specific context is needed"""
        if not pets:
            return False
        
        # Always use pet context for specific pet names
        for pet in pets:
            if pet.get("name", "").lower() in message.lower():
                return True
        
        # Use for general pet references
        pet_references = ["my dog", "my puppy", "my pet", "our dog", "the dog"]
        return any(ref in message.lower() for ref in pet_references)
    
    def _is_training_question(self, message: str) -> bool:
        """Detect training/behavior questions"""
        training_keywords = [
            "train", "training", "teach", "behavior", "obedience", "command",
            "sit", "stay", "come", "heel", "leash", "walk", "bark", "jump"
        ]
        return any(keyword in message.lower() for keyword in training_keywords)
    
    def _is_sensitive_topic(self, message: str) -> bool:
        """Detect sensitive topics that need empathetic handling"""
        sensitive_keywords = [
            "sick", "ill", "dying", "cancer", "tumor", "disease", "serious illness",
            "old", "aging", "senior", "elderly", "declining", "not doing well",
            "worried", "scared", "frightened", "anxious", "stressed", "upset",
            "sad", "heartbroken", "devastated", "grief", "mourning",
            "vet said", "diagnosis", "prognosis", "bad news", "terminal"
        ]
        return any(keyword in message.lower() for keyword in sensitive_keywords)
    
    def _involves_pet_loss(self, message: str) -> bool:
        """Detect mentions of pet death or loss"""
        loss_keywords = [
            "passed away", "died", "death", "dead", "lost", "gone",
            "put down", "put to sleep", "euthanized", "euthanasia",
            "rainbow bridge", "crossed over", "no longer with us",
            "said goodbye", "final goodbye", "last moments",
            "heaven", "passed", "departed", "rest in peace", "rip"
        ]
        
        # Also check for past tense references with pet names
        message_lower = message.lower()
        
        # Direct loss keywords
        if any(keyword in message_lower for keyword in loss_keywords):
            return True
        
        # Past tense patterns that might indicate loss
        past_tense_patterns = [
            "was my", "was a", "used to", "back when", "when he was alive",
            "when she was alive", "before he died", "before she died",
            "he's gone", "she's gone", "miss him", "miss her"
        ]
        
        return any(pattern in message_lower for pattern in past_tense_patterns)
    
    def _mentions_anahata(self, message: str) -> bool:
        """Detect mentions of Anahata or Way of Dog philosophy"""
        anahata_keywords = [
            "anahata", "way of dog", "way of the dog", 
            "interspecies culture", "intuitive bonding"
        ]
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in anahata_keywords)
    
    def _estimate_prompt_tokens(self, context: PromptContext) -> int:
        """Estimate tokens for the optimized prompt"""
        base_tokens = 15  # BASE_IDENTITY
        
        # Add estimated tokens for each module that would be used
        module_tokens = {
            "pet_specific": 12,
            "multi_pet": 15,
            "detailed_response": 10,
            "quick_response": 8,
            "health_safety": 15,
            "emergency": 20,
            "conversational": 8,
            "behavior_focus": 12,
            "breed_specific": 10,
            "context_memory": 10,
            "empathetic": 12,
            "pet_loss": 25,
            "memorial_questions": 20,
            "anahata_wisdom": 18
        }
        
        estimated = base_tokens
        if context.requires_pet_specific:
            estimated += module_tokens["pet_specific"]
        if context.is_health_related:
            estimated += module_tokens["health_safety"]
        if context.is_emergency:
            estimated += module_tokens["emergency"]
        if context.is_sensitive or context.involves_pet_loss:
            estimated += module_tokens["empathetic"]
            if context.involves_pet_loss:
                estimated += module_tokens["pet_loss"] + module_tokens["memorial_questions"]
            estimated += module_tokens["anahata_wisdom"]
        
        return estimated
    
    def _track_optimization(self, optimized_prompt: str, modules_used: List[str], context: PromptContext):
        """Track optimization metrics"""
        self.optimization_stats["total_requests"] += 1
        
        # Estimate old vs new token usage
        old_tokens = 1000  # Approximate size of current massive prompt
        new_tokens = len(optimized_prompt.split()) * 1.3  # Rough token estimation
        
        tokens_saved = old_tokens - new_tokens
        self.optimization_stats["tokens_saved"] += tokens_saved
        self.optimization_stats["old_prompt_tokens"] += old_tokens
        self.optimization_stats["new_prompt_tokens"] += new_tokens
        
        # Track module usage
        for module in modules_used:
            self.optimization_stats["module_usage"][module] = \
                self.optimization_stats["module_usage"].get(module, 0) + 1
        
        # Track response types
        response_type = context.response_type.value
        self.optimization_stats["response_types"][response_type] = \
            self.optimization_stats["response_types"].get(response_type, 0) + 1
        
        # Calculate cost savings (assuming $0.002 per 1K tokens for GPT-4)
        cost_saved = (tokens_saved / 1000) * 0.002
        self.optimization_stats["cost_savings"] += cost_saved
        
        logger.debug(f"ðŸ’° Optimization: {tokens_saved} tokens saved, ${cost_saved:.4f} cost reduction")
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """Get comprehensive optimization statistics"""
        if self.optimization_stats["total_requests"] == 0:
            return {"message": "No optimization data available yet"}
        
        total_requests = self.optimization_stats["total_requests"]
        tokens_saved = self.optimization_stats["tokens_saved"]
        cost_savings = self.optimization_stats["cost_savings"]
        
        avg_tokens_saved = tokens_saved / total_requests
        avg_old_tokens = self.optimization_stats["old_prompt_tokens"] / total_requests
        avg_new_tokens = self.optimization_stats["new_prompt_tokens"] / total_requests
        
        reduction_percentage = ((avg_old_tokens - avg_new_tokens) / avg_old_tokens) * 100
        
        return {
            "optimization_summary": {
                "total_requests_optimized": total_requests,
                "total_tokens_saved": tokens_saved,
                "total_cost_savings": f"${cost_savings:.4f}",
                "average_tokens_saved_per_request": int(avg_tokens_saved),
                "token_reduction_percentage": f"{reduction_percentage:.1f}%",
                "estimated_monthly_savings": f"${cost_savings * 30:.2f}"
            },
            "performance_metrics": {
                "average_old_prompt_size": int(avg_old_tokens),
                "average_new_prompt_size": int(avg_new_tokens),
                "efficiency_improvement": f"{reduction_percentage:.1f}% smaller prompts",
                "status": "âœ… Smart Optimization Active"
            },
            "usage_patterns": {
                "most_used_modules": dict(sorted(
                    self.optimization_stats["module_usage"].items(),
                    key=lambda x: x[1], reverse=True
                )[:5]),
                "response_type_distribution": self.optimization_stats["response_types"]
            }
        }
    
    def reset_stats(self):
        """Reset optimization statistics"""
        self.optimization_stats = {
            "total_requests": 0,
            "tokens_saved": 0,
            "old_prompt_tokens": 0,
            "new_prompt_tokens": 0,
            "module_usage": {},
            "response_types": {},
            "cost_savings": 0.0
        }
        logger.info("ðŸ”„ Smart prompt optimization stats reset")

    def get_fallback_response(self, message: str) -> str:
        """Get fallback response for errors"""
        fallback_responses = [
            "I'd be happy to help with your dog question! Could you provide a bit more detail?",
            "That's a great question about dog care. Let me help you with that.",
            "I have experience with that type of situation. Could you elaborate a bit more?"
        ]
        
        import random
        base_response = random.choice(fallback_responses)
        
        if "train" in message.lower():
            return f"{base_response} Training is one of my specialties!"
        elif "health" in message.lower() or "sick" in message.lower():
            return f"{base_response} For health concerns, I always recommend consulting with a veterinarian."
        else:
            return base_response
